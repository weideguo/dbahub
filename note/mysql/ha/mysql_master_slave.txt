复制特性(replication)

中继日志(relay log)    
----(io_thread)从节点I/O线程将主节点的二进制日志读取并记录到从节点本地文件形成中继日志
--- (sql_thread)然后从节点SQL线程会读取relay_log日志的内容并应用到从服务器



【MASTER】
    设置唯一的server_id的值；
    必须启用二进制日志（设置【log_bin】参数）。
    
show master status\G;    ---查看主节点的状态
show slave hosts;        ---在主节点查看从节点的信息 
  从节点启动时需要加 
  report_host         --必须，其他则可选。从节点的ip，只是用于标识，并不实际使用该网络
  report_port         --从节点的端口
  report_user         --只是用于作为user的标识，并不需要跟从节点的账号相同
  report_password 
    
    
【SLAVE】
---设置唯一的server_id值；(slave节点可以自由确定是否启用二进制日志)
---配置slave到master的连接。
---应该设置中继日志
change master to
master_host='master_host',                -----
master_port=master_port,                  -----
master_user='master_user',                -----主节点的账号，并拥有replication slave权限（grant replication slave on *.* to 'master_user'@'host' identified by 'user_password'; 创建用户并赋予权限）
master_password='master_user_password',   -----
master_log_file='master_logfile',         -----在master中使用【show master status】查看
master_log_pos=master_position;           -----在master中使用【show master status】查看

show slave status\G;    ---查看从节点的状态


start slave sql_thread;  ---启动从节点sql线程
start slave io_thread;   ---启动从节点io线程

stop slave;   ---停止从节点的slave服务
start slave;  ---开启从节点的slave服务


出现告警 If a crash happens this configuration does not guarantee that the relay log info will be consistent, Error_code: 0
---在配置文件添加参数
在复制的slave节点会创建两个日志：master.info、relay-log.info。可以选择存放在文件(file)或者表(table)中。
slave启动时会读取master.info和relay-log.info确认从master读取relay log的情况。
io_thread线程维护master.info。
sql_thread线程维护relay-log.info。
或
set global master_info_repository='TABLE';
set global relay_log_info_repository='TABLE';



#从节点
Relay_Master_Log_File   SQL线程执行到的主节点的文件
Exec_Master_Log_Pos     SQL线程执行到的主节点的position


Master_Log_File         IO线程读取到的主节点的文件
Read_Master_Log_Pos     IO线程读取到的主节点的position


主从信息删除
1. reset master;                        ----删除所有二进制日志
2. purge master logs to 'log_name';     ----删除位于指定日志或日期之前的日志索引中的二进制日志。
3. purge master logs before 'date';     ----date格式：'YYYY-MM-DD hh:mm:ss'

reset slave all;    ---从库删除主从信息


联级复制  
slave节点启动二进制日志，并设置【--log-slave-updates】【--log_slave_updates】参数，由中继日志产生的数据库修改也会写到本地二进制日志
slave节点作为下一层级slave节点的master

由slave节点进行备份
将slave节点的sql_thread关闭，在slave节点执行mysqldump

半同步机制 (semisynchronous replication)
一主多从架构中至少一个slave几点接收到事务(io_thread同步即可),即可返回成功的信息
----启用半同步，需要预先安装半同步插件
----master安装 semisync_master.so
----slave安装 semisync_slave.so
rpl_semi_sync_master_enabled=on        ---master的设置
rpl_semi_sync_slave_status=on        ---slave的设置

                      
设置多线程复制
set global slave_parallel_workers=30                      




set slave_parallel_type="LOGICAL_CLOCK"       -- 5.7.2 引入 默认DATABASE
Transactions that are part of the same binary log group commit on a master are applied in parallel on a slave. 
默认DATABASE为库级别的并发


atomic commitment protocol,APC
两阶段提交 (two-phase commit,2PC)
msater提交事务后，等slave节点提交完毕



延时复制
slave节点中
change master to master_delay=n;   ----n为延时的秒


多源复制 mulit source replication 5.6以上支持
一个从库可以有多个主库
change master to master_host='127.0.0.1'
,master_port=3306
,master_user='root'
,master_password=''
,master_auto_position=1     --也可以使用传统的指定binlog文件名及position确定复制点
for channel 'master_2';


--mysql5.7
--可以实现不重启设置过滤以及库名转换
--mysql5.1不持支这个语法
CHANGE REPLICATION FILTER filte
filter:
    REPLICATE_DO_DB = (db_list)
  | REPLICATE_IGNORE_DB = (db_list)
  | REPLICATE_DO_TABLE = (tbl_list)
  | REPLICATE_IGNORE_TABLE = (tbl_list)
  | REPLICATE_WILD_DO_TABLE = (wild_tbl_list)
  | REPLICATE_WILD_IGNORE_TABLE = (wild_tbl_list)
  | REPLICATE_REWRITE_DB = (db_pair_list)                      
                      

    
使用 master_log_file/master_log_pos复制跳过
--slave_skip_errors                                              ----on/off或者其他 必须在启动时设置
stop slave;set global sql_slave_skip_counter=1;start slave;      ----跳过的事件数 可以直接在mysql运行时执行

replicate-do-db 在配置文件中写时必须一行对应一个库，多个库则使用多行。binlog为row格式时，不在对应库的跨库DML可以被复制，但不在对应库的跨库DDL不能；为statement时不在对应库的跨库SQL不会被复制。

replicate-wild-do-table binlog为statement时，使用这个代理库级别复制过滤可能更安全，从而实现对跨库操作的支持。

库级别过滤为空或者匹配库级别过滤，才会继续匹配表级别过滤


使用master_auto_position复制跳过

#在slave中 执行空事务实现复制跳过 
STOP SLAVE;
SET SESSION GTID_NEXT = <gtid-to-skip>;                 # aaaaaa-bbbb-cccc-dddd-eeeeeeeee:2009911511   要为已经执行的gtid+1
BEGIN; COMMIT;                                          # 这个事务的gtid即为上面设置的值，执行这个之后 在改实例 show master status 立即体现，因为改gtid已经存在，索引binlog中这个gtid对应的事务不再执行
SET SESSION GTID_NEXT = AUTOMATIC;
START SLAVE;

# <gtid-to-skip> 为binlog中需要跳过复制的gtid 即通过指定下一个事务的gtid，实现复制跳过。需要查看主库的binlog确定要跳过的事务的gtid。
# 在主库直接mysqlbinlog命令还原binlog查看、或者在主库通过show binlog events in ... 查看、或者在从库通过show relaylog events in ... 查看
# 或 slave slave status\G 中获取 Master_UUID 、 Executed_Gtid_Set ，通过 Master_UUID 确定最后执行的gtid偏移量，拼接成要跳过的gtid（级联复制时需要参考Retrieved_Gtid_Set确定binlog真正的来源master）

show global variables like 'gtid_executed';             # aaaaaa-bbbb-cccc-dddd-eeeeeeeee:1-2009911510 已经执行过的gtid
                                                    
Executed_Gtid_Set                                       # slave slave status\G ，值与 gtid_executed 相同


# 新建从实例时需要运行
# 设置从库开始复制gtid
reset master;
set global gtid_purged=<gtid-to-begin-replication>      # aaaaaa-bbbb-cccc-dddd-eeeeeeeee:1-2009911510   在主库 show master status 可以确定该值，即已经执行的gtid，在复制时跳过
show master status;                                     # 应该跟gtid_purged设置的值一致
CHANGE MASTER TO ... master_auto_position=1;
start slave;






mysql> show slave status\G
*************************** 1. row ***************************
              Master_Log_File: mysql.000003                       #读取到的master的binlog文件                     master.info文件的第2行
          Read_Master_Log_Pos: 120                                #读取到的master的pos                            master.info文件的第3行
               Relay_Log_File: localhost-relay-bin.000001         #本地的正在被恢复relay文件                      relay-log.info文件的第2行
                Relay_Log_Pos: 4                                  #本地的正在被恢复relay的pos                     relay-log.info文件的第3行
        Relay_Master_Log_File: mysql.000003                       #本地的正在被恢复relay对应的master的binlog文件  relay-log.info文件的第4行
                                                                  #
          Exec_Master_Log_Pos: 120                                #已经执行master的pos                            relay-log.info文件的第5行
              Relay_Log_Space: 20187680                           #本地relay log的大小，已经执行的会自动清理




################
使用binlog伪装成relay log实现多线程导入

1.复制master的binlog到本地的relay log目录，并重命名为relay log格式，将文件名添加到relay-bin.index
2.修改relay-log.info 第2第3行，第4第5行，指定恢复的起始点。（可以通过change master to ... 命令设置）
3.修改relay-log.info 第2第3行，指定恢复的结束点。


##注意##
#不要启用gtid
set global gtid_mode=off
#中继信息使用文件记录
set global relay_log_info_repository =FILE;

#通过设置复制并发数加快恢复过程
set global slave_parallel_workers=100




###############
通过复制目录重新创建从库，可能因为主机名不同导致relay读取失败（默认relay log名由主机名确定）
reset slave;             #清空主从信息（注意先保存已经同步好的信息）






--8.0.22以及以后的操作
START REPLICA ;        ---代替 START SLAVE     


--8.0.23以及以后 代替change master to
CHANGE REPLICATION SOURCE TO option [, option] ... [ channel_option ]

option: {
    SOURCE_BIND = 'interface_name'
    
  | SOURCE_HOST = 'host_name'
  | SOURCE_USER = 'user_name'
  | SOURCE_PASSWORD = 'password'
  | SOURCE_PORT = port_num
  
  | PRIVILEGE_CHECKS_USER = {'account' | NULL}
  | REQUIRE_ROW_FORMAT = {0|1}
  | REQUIRE_TABLE_PRIMARY_KEY_CHECK = {STREAM | ON | OFF}
  | ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS = {OFF | LOCAL | uuid}
  
  | SOURCE_LOG_FILE = 'source_log_name'
  | SOURCE_LOG_POS = source_log_pos
  | SOURCE_AUTO_POSITION = {0|1}
  
  | RELAY_LOG_FILE = 'relay_log_name'
  | RELAY_LOG_POS = relay_log_pos
  | SOURCE_HEARTBEAT_PERIOD = interval
  | SOURCE_CONNECT_RETRY = interval
  | SOURCE_RETRY_COUNT = count
  | SOURCE_CONNECTION_AUTO_FAILOVER = {0|1}
  | SOURCE_DELAY = interval
  | SOURCE_COMPRESSION_ALGORITHMS = 'value'
  | SOURCE_ZSTD_COMPRESSION_LEVEL = level
  
  | SOURCE_SSL = {0|1}
  | SOURCE_SSL_CA = 'ca_file_name'
  | SOURCE_SSL_CAPATH = 'ca_directory_name'
  | SOURCE_SSL_CERT = 'cert_file_name'
  | SOURCE_SSL_CRL = 'crl_file_name'
  | SOURCE_SSL_CRLPATH = 'crl_directory_name'
  | SOURCE_SSL_KEY = 'key_file_name'
  | SOURCE_SSL_CIPHER = 'cipher_list'
  | SOURCE_SSL_VERIFY_SERVER_CERT = {0|1}
  | SOURCE_TLS_VERSION = 'protocol_list'
  | SOURCE_TLS_CIPHERSUITES = 'ciphersuite_list'
  | SOURCE_PUBLIC_KEY_PATH = 'key_file_name'
  | GET_SOURCE_PUBLIC_KEY = {0|1}
  
  | NETWORK_NAMESPACE = 'namespace'
  | IGNORE_SERVER_IDS = (server_id_list)
}

channel_option:
    FOR CHANNEL channel

server_id_list:
    [server_id [, server_id] ... ]
    
    
 
