使用文件存储


分布式流式处理 如日志收集

每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。

topic中的数据分割为一个或多个partition。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。
每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。Follower跟随Leader。

Kafka 集群包含一个或多个服务器，服务器节点称为broker。broker存储topic的数据。




kafka保存消费者消费的进度，即offset

当offset不存在时，根据auto.offset.reset配置的值，会有几种不同策略
earliest
无指定的offset时，从头开始消费

latest
无提交的offset时，消费该分区下最新产生的消息

none
topic不存在指定的offset，则抛出异常




点对点消息传递模式           一条消息只能被消费一次
发布-订阅消息传递模式       同一条数据可以被多个消费者消费





#集群配置
#config/server.properties

broker.id=1              #唯一即可，连接共同的zookeeper即成为一个集群
log.dirs                 #日志路径 实际存储topic数据
zookeeper.connect        #连接的zookeeper集群



# 启用删除主题
delete.topic.enable=true
# 检查日志段文件的间隔时间，以确定是否文件属性是否到达删除要求。
log.retention.check.interval.ms=1000


# 启动
bin/kafka-server-start.sh -daemon config/server.properties

# 关闭
bin/kafka-server-stop.sh


# 列出所有topic
./bin/kafka-topics.sh --bootstrap-server localhost:9092 --list 

# 消费组
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

# 查看指定消费组的消费情况
./bin/kafka-consumer-groups.sh --describe --bootstrap-server 127.0.0.1:9092 --group  <group_name>

# 查看指定topic的信息
./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092  --describe --topic <topic_name>

# 创建topic
./bin/kafka-topics.sh --create \
    --zookeeper <Zookeeper quorum> \
    --replication-factor <number of replicas> \
    --partitions <number of partitions> \
    --topic <topic name>

./bin/kafka-topics.sh --create \
    --bootstrap-server localhost:9092 \
    --topic <topic_name> \
    --partitions 3 \
    --replication-factor 2

# 修改topic
kafka-topics.sh --alter  ...  
    
# replication-factor    副本数
# partitions            分区数

